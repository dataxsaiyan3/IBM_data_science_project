{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d4a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas and numpy libraries to work with dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Importing KMeans cluster model \n",
    "# Importing matplotlib for plotting the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn for a prittier visulisation\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the seoborn\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b81773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('data_with_pos_neg_neu_count_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc98440",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b649bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the columns that we will use to run the clustering model\n",
    "\n",
    "# First data will be used to find clusters based on the review and scores\n",
    "df_review_type = data[['score', 'thumbsUpCount', 'appName', 'Review type',\n",
    "          'word_count', 'positive_score', 'neutral_score', 'negative_score',\n",
    "          'compound_score']]\n",
    "\n",
    "# The second data will be used to find the fans of super cell apps and non-fans\n",
    "df_fans = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3429bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at</th>\n",
       "      <th>_id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>appName</th>\n",
       "      <th>Review type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>compound_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-01 20:20:03</td>\n",
       "      <td>60a23abbdb692423c850ebfe</td>\n",
       "      <td>gp:AOqpTOGO6dnp27Rv8vCY2ppHTTw27o2rCkYt1FoqVOd...</td>\n",
       "      <td>Apple Sauce</td>\n",
       "      <td>I used to think of this as a 5star game (and I...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Boom Beach</td>\n",
       "      <td>Negative</td>\n",
       "      <td>25</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-01 14:03:39</td>\n",
       "      <td>60a23abbdb692423c850ec05</td>\n",
       "      <td>gp:AOqpTOFNqMfAngyP8SdCxwZosjvNxM7DdErLS4pywK5...</td>\n",
       "      <td>shajeedullah kaisar</td>\n",
       "      <td>I like Boom Beach</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Boom Beach</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-01 21:02:00</td>\n",
       "      <td>60a23abbdb692423c850ebfc</td>\n",
       "      <td>gp:AOqpTOFP7HzBTwV7MD_yn1vsFkonLge2NCxaKbrOLW1...</td>\n",
       "      <td>ragin wi'll gamin</td>\n",
       "      <td>A verry good game fun and entertaining</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Boom Beach</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    at                       _id  \\\n",
       "0  2021-05-01 20:20:03  60a23abbdb692423c850ebfe   \n",
       "1  2021-05-01 14:03:39  60a23abbdb692423c850ec05   \n",
       "2  2021-05-01 21:02:00  60a23abbdb692423c850ebfc   \n",
       "\n",
       "                                            reviewId             userName  \\\n",
       "0  gp:AOqpTOGO6dnp27Rv8vCY2ppHTTw27o2rCkYt1FoqVOd...          Apple Sauce   \n",
       "1  gp:AOqpTOFNqMfAngyP8SdCxwZosjvNxM7DdErLS4pywK5...  shajeedullah kaisar   \n",
       "2  gp:AOqpTOFP7HzBTwV7MD_yn1vsFkonLge2NCxaKbrOLW1...    ragin wi'll gamin   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  I used to think of this as a 5star game (and I...      2              0   \n",
       "1                                  I like Boom Beach      5              0   \n",
       "2             A verry good game fun and entertaining      5              0   \n",
       "\n",
       "      appName Review type  word_count  positive_score  neutral_score  \\\n",
       "0  Boom Beach    Negative          25           0.076          0.924   \n",
       "1  Boom Beach    Positive           4           0.556          0.444   \n",
       "2  Boom Beach    Positive           7           0.752          0.248   \n",
       "\n",
       "   negative_score  compound_score  \n",
       "0             0.0          0.2023  \n",
       "1             0.0          0.3612  \n",
       "2             0.0          0.8442  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we drop the appId column because we have the appName and that is the same information\n",
    "# We also drop the count column because we used earlier when grouping\n",
    "df_fans.drop(['appId', 'count'], axis = 1, inplace = True)\n",
    "df_fans.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8c018",
   "metadata": {},
   "source": [
    "### For the first dataset df review type:\n",
    "\n",
    "#### I decided to remove the ID, date, and user name from the data that will be used for the clustering model. The ID and user name will not help me because it doesnt have any added value to the model, it will just cause the model to only work with this data set because these unique ID cannot be generalised with other data.\n",
    "\n",
    "#### I have also removed the content because we already got numerical interpretation of the content and that what we need for this model\n",
    "\n",
    "#### I have removed the date because it might mislead the model by choosing clusters based on the date and thats not the aim of this dataset. The aim of this dataset is to find the cluster of review types based on the scores and content. This will help us later to identify how positive and how negative the review is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d50bb",
   "metadata": {},
   "source": [
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdef222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First data will be used to find clusters based on the review and scores\n",
    "df_review_score = data[['score', 'compound_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fa7f2",
   "metadata": {},
   "source": [
    "### First we create a new column to devine the target for a classification prediction, we will create 8 categories based on the score and content compound score.  The compound score measure how positive is the content, given, +1 is very positive and -1 is very negative:\n",
    "\n",
    "#### 1 = Super negative,\n",
    "#### 2 = Very Negative\n",
    "#### 3 = Negative\n",
    "#### 4 = Neutral Negative\n",
    "#### 5 = Neutral Postitive\n",
    "#### 6 = Postitive\n",
    "#### 7 = Very Positive \n",
    "#### 8 = Super Postive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f3a61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-83224aeb2264>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_score['review_type'] = np.select(condetions, categories)\n",
      "<ipython-input-6-83224aeb2264>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_score['review_type_encoded'] = np.select(condetions, categories_encoded)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298454</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298455</th>\n",
       "      <td>5</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298456</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.5499</td>\n",
       "      <td>Super negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298457</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2958</td>\n",
       "      <td>Super positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298458</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Super negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1298459 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  compound_score     review_type review_type_encoded\n",
       "0            2          0.2023        Negative                   3\n",
       "1            5          0.3612  Super positive                   8\n",
       "2            5          0.8442  Super positive                   8\n",
       "3            5          0.4404  Super positive                   8\n",
       "4            5          0.9806  Super positive                   8\n",
       "...        ...             ...             ...                 ...\n",
       "1298454      5         -0.4215  Super positive                   8\n",
       "1298455      5          0.4939  Super positive                   8\n",
       "1298456      1         -0.5499  Super negative                   1\n",
       "1298457      5          0.2958  Super positive                   8\n",
       "1298458      1          0.0000  Super negative                   1\n",
       "\n",
       "[1298459 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we create a list of our conditions\n",
    "\n",
    "condetions = [\n",
    "    # score equal to 1 is Super negative review\n",
    "    (df_review_score['score'] == 1),\n",
    "    # score equal to 2, and a compound_score lower or equal to 0 is a very negative review\n",
    "    (df_review_score['score'] == 2) & (df_review_score['compound_score'] <= 0),\n",
    "    # score equal to 2, and a compound_score bigger than 0 is a Negative review\n",
    "    (df_review_score['score'] == 2) & (df_review_score['compound_score'] > 0),\n",
    "    # score equal to 3, and a compound_score lower or equal to 0 is a Neutral Negative review\n",
    "    (df_review_score['score'] == 3) & (df_review_score['compound_score'] <= 0),\n",
    "    # score equal to 3, and a compound_score bigger than 0 is a Neutral positive review\n",
    "    (df_review_score['score'] == 3) & (df_review_score['compound_score'] > 0),\n",
    "    # score equal to 4, and a compound_score lower than 0 is a positive review\n",
    "    (df_review_score['score'] == 4) & (df_review_score['compound_score'] <= 0),\n",
    "    # score equal to 4, and a compound_score lower than 0 is a very positive review\n",
    "    (df_review_score['score'] == 4) & (df_review_score['compound_score'] > 0),\n",
    "    # score equal to 5 is Super positive review\n",
    "    (df_review_score['score'] == 5)\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each condition respectively\n",
    "categories = ['Super negative', 'Very negative', 'Negative', 'Neutral Negative', 'Neutral positive', 'Positive',\n",
    "         'Very positive', 'Super positive']\n",
    "\n",
    "categories_encoded = ['1', '2', '3', '4', '5', '6',\n",
    "         '7', '8']\n",
    "\n",
    "df_review_score['review_type'] = np.select(condetions, categories)\n",
    "df_review_score['review_type_encoded'] = np.select(condetions, categories_encoded)\n",
    "df_review_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ab1f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score                  0\n",
       "compound_score         0\n",
       "review_type            0\n",
       "review_type_encoded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any missing values\n",
    "df_review_score.isnull().sum()\n",
    "# Perfect no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17218a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Super positive      940057\n",
       "Super negative      148294\n",
       "Very positive        81952\n",
       "Neutral positive     39292\n",
       "Positive             37926\n",
       "Negative             21163\n",
       "Neutral Negative     19178\n",
       "Very negative        10597\n",
       "Name: review_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the count of review types categories \n",
    "df_review_score['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b47f8",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886f96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numeric columns as Machine Learning cannot handle categorical values without encoding\n",
    "df_review_score_only_numeric = df_review_score[['score', 'compound_score', 'review_type_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bcbaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1298459 entries, 0 to 1298458\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   score                1298459 non-null  int64  \n",
      " 1   compound_score       1298459 non-null  float64\n",
      " 2   review_type_encoded  1298459 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 29.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the information of the data\n",
    "df_review_score_only_numeric.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388653ab",
   "metadata": {},
   "source": [
    "#### We will need to change the data type of the review type encoded to an integer so that it can be recognised as a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4e874d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-2241e96a163a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_score_only_numeric['review_type_encoded'] = df_review_score_only_numeric['review_type_encoded'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Changing the data type of review_type_encoded to an integer\n",
    "df_review_score_only_numeric['review_type_encoded'] = df_review_score_only_numeric['review_type_encoded'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8f1f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1298459 entries, 0 to 1298458\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   score                1298459 non-null  int64  \n",
      " 1   compound_score       1298459 non-null  float64\n",
      " 2   review_type_encoded  1298459 non-null  int32  \n",
      "dtypes: float64(1), int32(1), int64(1)\n",
      "memory usage: 24.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking if the the review_type_encoded changed to an integer\n",
    "df_review_score_only_numeric.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504054e",
   "metadata": {},
   "source": [
    "#### Now we can start using the data to run a classification model and predict the review type based on the score and content compound score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f59d9",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5245d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the StandardScaler to scale the data because we are using Logistics regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "df_scaled_independent = sc.fit_transform(df_review_score_only_numeric[['score', 'compound_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77bed9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.69922293, -0.34913103],\n",
       "       [ 0.52935767,  0.04662976],\n",
       "       [ 0.52935767,  1.24960309],\n",
       "       ...,\n",
       "       [-2.44208313, -2.22258143],\n",
       "       [ 0.52935767, -0.11625731],\n",
       "       [-2.44208313, -0.85298508]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the scaled dataset\n",
    "df_scaled_independent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336c868",
   "metadata": {},
   "source": [
    "#### Splitting the data first into a training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b07959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import train_test_split so that we divide the data into a training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting the X values as the independent variables and y values as the dependent variable\n",
    "X = df_scaled_independent[:, :2]\n",
    "y = df_review_score_only_numeric['review_type_encoded']\n",
    "\n",
    "# Splitting the data into training and test set\n",
    "# I will set a side 20% of the data as a test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Creating a validation data set from the traning data\n",
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09414f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831013, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(831013,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(207754, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(207754,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(259692, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(259692,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the shape of the the x and y data\n",
    "\n",
    "# The training data that will be used for model traning\n",
    "display(X_train_2.shape)\n",
    "display(y_train_2.shape)\n",
    "\n",
    "# The validation data that will be used for model evaluation\n",
    "display(X_val.shape)\n",
    "display(y_val.shape)\n",
    "\n",
    "\n",
    "# The test data that will be used to test the model\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddb6c9",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f447e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These samples were used to speed up the process of modelling\n",
    "# It helped in picking the right model, which is in this case KNeighborsClassifier\n",
    "X_sample = X_train_2[:3000, :]\n",
    "y_sample = y_train_2[:3000]\n",
    "X_sample_v = X_val[:3000, :]\n",
    "y_sample_v = y_val[:3000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428e1ed",
   "metadata": {},
   "source": [
    "## Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96073a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNeighbors = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 8)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "KNeighbors.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Predict the labels of the validation set: y_pred\n",
    "y_pred = KNeighbors.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22652e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23640      0      0      0      0      0      0      0]\n",
      " [     0   1641      0      0      0      0      0      0]\n",
      " [     0      1   3410      0      0      0      0      0]\n",
      " [     0      0      0   3029      0      0      0      0]\n",
      " [     0      0      0      0   6371      0      0      0]\n",
      " [     0      0      0      0      0   5987      0      0]\n",
      " [     0      0      0      0      0      0  13123      0]\n",
      " [     0      0      0      0      0      0      0 150552]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999951866149388"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50972248",
   "metadata": {},
   "source": [
    "## Testing the model on the test dataset for more accurate evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4ccc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all = KNeighbors.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f658f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29675      0      0      0      0      0      0      0]\n",
      " [     0   2138      0      0      0      0      0      0]\n",
      " [     0      2   4183      0      0      0      0      0]\n",
      " [     0      0      0   3686      0      0      0      0]\n",
      " [     0      0      0      0   7898      0      0      0]\n",
      " [     0      0      0      0      0   7734      0      0]\n",
      " [     0      0      0      0      0      0  16328      0]\n",
      " [     0      0      0      0      0      0      0 188048]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999922985690741"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_all)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754acc2",
   "metadata": {},
   "source": [
    "## The model is very accurate for the test and validation dataset so there is no need to do hyperparameter tuning or cross validation. However I will use Neural network to complete the requirements of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee06473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the dataset \n",
    "df_review_score_only_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d542b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import Keras as it will be the library to use for Neural network\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bc3b7",
   "metadata": {},
   "source": [
    "#### First we create an early stop for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a29ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing EarlyStopping to stop the model from training of the model is not improving\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# setting up the stop after 3 tries of the model is not improving\n",
    "# It is important because this will save a lot of time and prevent the model from over fitting\n",
    "stop = EarlyStopping(monitor = 'val_loss', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Sequential and Dense libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initiating the model Sequentialy \n",
    "model = Sequential()\n",
    "\n",
    "# Creating the layers, using the activation='relu' and 1, activation='sigmoid' for the last layer\n",
    "model.add(Dense(12, input_shape= (len(df_review_score_only_numeric.columns)-1,), activation='relu'))\n",
    "model.add(Dense(30,activation='softmax'))\n",
    "model.add(Dense(10,activation='softmax'))  \n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "# Using softmax because we are dealing with a calssification problem\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# Compiling the model and using binary_crossentropy because binary_crossentropy is used for classifications problems\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_2, y_train_2, epochs=10, batch_size=32,\n",
    "          validation_data= (X_val, y_val), callbacks=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4d059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
